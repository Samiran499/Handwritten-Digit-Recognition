{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Digit Recignition\n",
    "In this notebook, I'll try to code it on a more tensorflow way. I'm not saving the model after the training. So, everytime the kernel restarts, it needs to trained. Feel free to change the hyperparameters, but for me these values feel good enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model as subclass of Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigiRecModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(DigiRecModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.dropout1 = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.dropout2 = tf.keras.layers.Dropout(0.25)\n",
    "\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.dropout3 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, inputs): # Override the tensorflow call function\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout3(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I'm loading the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train datasets\n",
    "train_x = np.loadtxt(\"Dataset/train_X.csv\", delimiter=',')\n",
    "train_y = np.loadtxt(\"Dataset/train_label.csv\", delimiter=',')\n",
    "\n",
    "train_x = train_x.reshape(1000, 28, 28, 1) / 255.0\n",
    "\n",
    "# Test datasets\n",
    "test_x = np.loadtxt(\"Dataset/test_X.csv\", delimiter=',')\n",
    "test_y = np.loadtxt(\"Dataset/test_label.csv\", delimiter=',')\n",
    "\n",
    "test_x = test_x.reshape(350, 28, 28, 1) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the hyperparametrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samiran\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = DigiRecModel()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "batch_size = 1024\n",
    "epochs = 100\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Step 0: Loss = 0.002364872954785824\n",
      "Epoch 2/100\n",
      "Step 0: Loss = 0.002301508327946067\n",
      "Epoch 3/100\n",
      "Step 0: Loss = 0.0022410950623452663\n",
      "Epoch 4/100\n",
      "Step 0: Loss = 0.0021834848448634148\n",
      "Epoch 5/100\n",
      "Step 0: Loss = 0.0021285596303641796\n",
      "Epoch 6/100\n",
      "Step 0: Loss = 0.0020761003252118826\n",
      "Epoch 7/100\n",
      "Step 0: Loss = 0.0020258817821741104\n",
      "Epoch 8/100\n",
      "Step 0: Loss = 0.0019777684938162565\n",
      "Epoch 9/100\n",
      "Step 0: Loss = 0.001931674312800169\n",
      "Epoch 10/100\n",
      "Step 0: Loss = 0.0018874863162636757\n",
      "Epoch 11/100\n",
      "Step 0: Loss = 0.0018450162606313825\n",
      "Epoch 12/100\n",
      "Step 0: Loss = 0.0018042037263512611\n",
      "Epoch 13/100\n",
      "Step 0: Loss = 0.0017650024965405464\n",
      "Epoch 14/100\n",
      "Step 0: Loss = 0.001727242604829371\n",
      "Epoch 15/100\n",
      "Step 0: Loss = 0.0016908623510971665\n",
      "Epoch 16/100\n",
      "Step 0: Loss = 0.0016558181960135698\n",
      "Epoch 17/100\n",
      "Step 0: Loss = 0.0016220082761719823\n",
      "Epoch 18/100\n",
      "Step 0: Loss = 0.0015893707750365138\n",
      "Epoch 19/100\n",
      "Step 0: Loss = 0.0015578654129058123\n",
      "Epoch 20/100\n",
      "Step 0: Loss = 0.0015274358447641134\n",
      "Epoch 21/100\n",
      "Step 0: Loss = 0.0014979700790718198\n",
      "Epoch 22/100\n",
      "Step 0: Loss = 0.0014694435521960258\n",
      "Epoch 23/100\n",
      "Step 0: Loss = 0.0014417989877983928\n",
      "Epoch 24/100\n",
      "Step 0: Loss = 0.0014150271890684962\n",
      "Epoch 25/100\n",
      "Step 0: Loss = 0.0013891091803088784\n",
      "Epoch 26/100\n",
      "Step 0: Loss = 0.001363943563774228\n",
      "Epoch 27/100\n",
      "Step 0: Loss = 0.0013394990237429738\n",
      "Epoch 28/100\n",
      "Step 0: Loss = 0.0013157589128240943\n",
      "Epoch 29/100\n",
      "Step 0: Loss = 0.0012926853960379958\n",
      "Epoch 30/100\n",
      "Step 0: Loss = 0.0012702782405540347\n",
      "Epoch 31/100\n",
      "Step 0: Loss = 0.0012484993785619736\n",
      "Epoch 32/100\n",
      "Step 0: Loss = 0.0012273190077394247\n",
      "Epoch 33/100\n",
      "Step 0: Loss = 0.0012067267671227455\n",
      "Epoch 34/100\n",
      "Step 0: Loss = 0.0011866920394822955\n",
      "Epoch 35/100\n",
      "Step 0: Loss = 0.001167205278761685\n",
      "Epoch 36/100\n",
      "Step 0: Loss = 0.0011482172412797809\n",
      "Epoch 37/100\n",
      "Step 0: Loss = 0.0011297102319076657\n",
      "Epoch 38/100\n",
      "Step 0: Loss = 0.0011116416426375508\n",
      "Epoch 39/100\n",
      "Step 0: Loss = 0.001094023697078228\n",
      "Epoch 40/100\n",
      "Step 0: Loss = 0.0010768384672701359\n",
      "Epoch 41/100\n",
      "Step 0: Loss = 0.0010600684909150004\n",
      "Epoch 42/100\n",
      "Step 0: Loss = 0.001043683267198503\n",
      "Epoch 43/100\n",
      "Step 0: Loss = 0.0010276803513988853\n",
      "Epoch 44/100\n",
      "Step 0: Loss = 0.001012043678201735\n",
      "Epoch 45/100\n",
      "Step 0: Loss = 0.0009967704536393285\n",
      "Epoch 46/100\n",
      "Step 0: Loss = 0.0009818354155868292\n",
      "Epoch 47/100\n",
      "Step 0: Loss = 0.0009672550950199366\n",
      "Epoch 48/100\n",
      "Step 0: Loss = 0.0009529944509267807\n",
      "Epoch 49/100\n",
      "Step 0: Loss = 0.0009390526101924479\n",
      "Epoch 50/100\n",
      "Step 0: Loss = 0.0009254152537323534\n",
      "Epoch 51/100\n",
      "Step 0: Loss = 0.0009120588074438274\n",
      "Epoch 52/100\n",
      "Step 0: Loss = 0.0008989996858872473\n",
      "Epoch 53/100\n",
      "Step 0: Loss = 0.0008862139075063169\n",
      "Epoch 54/100\n",
      "Step 0: Loss = 0.0008736843010410666\n",
      "Epoch 55/100\n",
      "Step 0: Loss = 0.0008614197722636163\n",
      "Epoch 56/100\n",
      "Step 0: Loss = 0.0008494140929542482\n",
      "Epoch 57/100\n",
      "Step 0: Loss = 0.0008376566111110151\n",
      "Epoch 58/100\n",
      "Step 0: Loss = 0.0008261328330263495\n",
      "Epoch 59/100\n",
      "Step 0: Loss = 0.0008148454362526536\n",
      "Epoch 60/100\n",
      "Step 0: Loss = 0.0008037911029532552\n",
      "Epoch 61/100\n",
      "Step 0: Loss = 0.0007929687271825969\n",
      "Epoch 62/100\n",
      "Step 0: Loss = 0.000782356015406549\n",
      "Epoch 63/100\n",
      "Step 0: Loss = 0.0007719469722360373\n",
      "Epoch 64/100\n",
      "Step 0: Loss = 0.0007617505616508424\n",
      "Epoch 65/100\n",
      "Step 0: Loss = 0.0007517507765442133\n",
      "Epoch 66/100\n",
      "Step 0: Loss = 0.0007419469184242189\n",
      "Epoch 67/100\n",
      "Step 0: Loss = 0.0007323219906538725\n",
      "Epoch 68/100\n",
      "Step 0: Loss = 0.0007228737813420594\n",
      "Epoch 69/100\n",
      "Step 0: Loss = 0.0007136143976822495\n",
      "Epoch 70/100\n",
      "Step 0: Loss = 0.0007045267266221344\n",
      "Epoch 71/100\n",
      "Step 0: Loss = 0.0006956125725992024\n",
      "Epoch 72/100\n",
      "Step 0: Loss = 0.0006868686177767813\n",
      "Epoch 73/100\n",
      "Step 0: Loss = 0.0006782870041206479\n",
      "Epoch 74/100\n",
      "Step 0: Loss = 0.0006698465440422297\n",
      "Epoch 75/100\n",
      "Step 0: Loss = 0.0006615614984184504\n",
      "Epoch 76/100\n",
      "Step 0: Loss = 0.0006534277927130461\n",
      "Epoch 77/100\n",
      "Step 0: Loss = 0.0006454373360611498\n",
      "Epoch 78/100\n",
      "Step 0: Loss = 0.0006375942029990256\n",
      "Epoch 79/100\n",
      "Step 0: Loss = 0.0006298830267041922\n",
      "Epoch 80/100\n",
      "Step 0: Loss = 0.0006223057862371206\n",
      "Epoch 81/100\n",
      "Step 0: Loss = 0.0006148663815110922\n",
      "Epoch 82/100\n",
      "Step 0: Loss = 0.0006075571291148663\n",
      "Epoch 83/100\n",
      "Step 0: Loss = 0.0006003690650686622\n",
      "Epoch 84/100\n",
      "Step 0: Loss = 0.0005933110951445997\n",
      "Epoch 85/100\n",
      "Step 0: Loss = 0.0005863748956471682\n",
      "Epoch 86/100\n",
      "Step 0: Loss = 0.0005795549950562418\n",
      "Epoch 87/100\n",
      "Step 0: Loss = 0.0005728474934585392\n",
      "Epoch 88/100\n",
      "Step 0: Loss = 0.0005662509938701987\n",
      "Epoch 89/100\n",
      "Step 0: Loss = 0.0005597656709142029\n",
      "Epoch 90/100\n",
      "Step 0: Loss = 0.0005533804069273174\n",
      "Epoch 91/100\n",
      "Step 0: Loss = 0.0005470985197462142\n",
      "Epoch 92/100\n",
      "Step 0: Loss = 0.0005409178556874394\n",
      "Epoch 93/100\n",
      "Step 0: Loss = 0.0005348398699425161\n",
      "Epoch 94/100\n",
      "Step 0: Loss = 0.000528857228346169\n",
      "Epoch 95/100\n",
      "Step 0: Loss = 0.0005229661474004388\n",
      "Epoch 96/100\n",
      "Step 0: Loss = 0.0005171674420125782\n",
      "Epoch 97/100\n",
      "Step 0: Loss = 0.0005114616942591965\n",
      "Epoch 98/100\n",
      "Step 0: Loss = 0.0005058404640294611\n",
      "Epoch 99/100\n",
      "Step 0: Loss = 0.0005003087571822107\n",
      "Epoch 100/100\n",
      "Step 0: Loss = 0.000494866631925106\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):  # Reduced epochs for simplicity\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    for step, (x_batch, y_batch) in enumerate(train_dataset):\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = model(x_batch, training=True)\n",
    "            loss = loss_fn(y_batch, predictions)\n",
    "\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print(f\"Step {step}: Loss = {loss.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset results \n",
      " Loss: 0.261959969997406 \n",
      " Accuracy: 0.9342857003211975\n"
     ]
    }
   ],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "accuracy_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "test_predictions = model(test_x, training=False)\n",
    "loss = loss_fn(test_y, test_predictions).numpy()\n",
    "accuracy_metric.update_state(test_y, test_predictions)\n",
    "accuracy = accuracy_metric.result().numpy()\n",
    "print(f\"Test dataset results \\n Loss: {loss} \\n Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted digit is 4\n"
     ]
    }
   ],
   "source": [
    "itr = int(input(\"How many examples do you want to see? \"))\n",
    "for _ in range(itr):\n",
    "    index = random.randint(0, len(test_y) - 1)\n",
    "    plt.imshow(test_x[index].reshape(28, 28), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    prediction_y = model(test_x[index:index + 1])\n",
    "    predicted_value = np.argmax(prediction_y.numpy())\n",
    "    print(\"The predicted digit is\", predicted_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
